{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/rfpred/notebooks/construction_work', '/home/rfpred/envs/rfenv/lib/python311.zip', '/home/rfpred/envs/rfenv/lib/python3.11', '/home/rfpred/envs/rfenv/lib/python3.11/lib-dynload', '', '/home/rfpred/envs/rfenv/lib/python3.11/site-packages', '/home/rfpred/notebooks/alien_nbs/lgnpy', '/home/rfpred/envs/rfenv/lib/python3.11/site-packages/nsd_access-0.0.1.dev0-py3.11.egg', '/home/rfpred/envs/rfenv/lib/python3.11/site-packages/cifti-1.1-py3.11.egg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cortex\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "import pickle\n",
    "import torchvision.models as models\n",
    "import nibabel as nib\n",
    "import h5py\n",
    "import copy\n",
    "import scipy.stats.mstats as mstats\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import argparse\n",
    "\n",
    "\n",
    "print(sys.path)\n",
    "%pwd\n",
    "\n",
    "os.chdir('/home/rfpred')\n",
    "sys.path.append('/home/rfpred/')\n",
    "sys.path.append('/home/rfpred/envs/rfenv/lib/python3.11/site-packages/')\n",
    "sys.path.append('/home/rfpred/envs/rfenv/lib/python3.11/site-packages/nsdcode')\n",
    "\n",
    "from classes.regdata import RegData\n",
    "from funcs.reloads import Reloader\n",
    "from classes.natspatpred import NatSpatPred\n",
    "from classes.voxelsieve import VoxelSieve\n",
    "from unet_recon.inpainting import UNet\n",
    "\n",
    "from funcs.rf_tools import make_circle_mask\n",
    "from funcs.imgproc import get_bounding_box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naturalistic Spatial Prediction class: \u001b[97mInitialised\u001b[0m\n",
      "\n",
      "Class contains the following attributes:\n",
      "\u001b[34m .analyse\u001b[0m\n",
      "\u001b[34m .attributes\u001b[0m\n",
      "\u001b[34m .cortex\u001b[0m\n",
      "\u001b[34m .datafetch\u001b[0m\n",
      "\u001b[34m .explore\u001b[0m\n",
      "\u001b[34m .hidden_methods\u001b[0m\n",
      "\u001b[34m .initialise\u001b[0m\n",
      "\u001b[34m .nsd_datapath\u001b[0m\n",
      "\u001b[34m .own_datapath\u001b[0m\n",
      "\u001b[34m .stimuli\u001b[0m\n",
      "\u001b[34m .subjects\u001b[0m\n",
      "\u001b[34m .utils\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "NSP = NatSpatPred()\n",
    "NSP.initialise(verbose=True)\n",
    "rl = Reloader()\n",
    "\n",
    "rois, roi_masks, viscortex_masks = NSP.cortex.visrois_dict(verbose=False)\n",
    "prf_dict = NSP.cortex.prf_dict(rois, roi_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = 2\n",
    "min_size = 0.15\n",
    "patchbound = 1\n",
    "min_nsd_R2 = 0\n",
    "min_prf_R2 = 0\n",
    "peri_angles = [90, 210, 330]\n",
    "angle = peri_angles[0]\n",
    "peri_ecc = 2.0\n",
    "startimg = 0\n",
    "endimg = 10\n",
    "# fixed_n_voxels = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now working on patch with angle 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1 voxels that fulfill requirements: \u001b[97m47\u001b[0m out of \u001b[97m7887\u001b[0m.\n",
      "V2 voxels that fulfill requirements: \u001b[97m52\u001b[0m out of \u001b[97m8296\u001b[0m.\n",
      "V3 voxels that fulfill requirements: \u001b[97m7\u001b[0m out of \u001b[97m7022\u001b[0m.\n",
      "V4 voxels that fulfill requirements: \u001b[97m11\u001b[0m out of \u001b[97m3976\u001b[0m.\n"
     ]
    }
   ],
   "source": [
    "# This voxeldict is not really needed, but I use it to get the exact matching\n",
    "# mask for the peripheral patch\n",
    "voxeldict = {}\n",
    "print(f\"Now working on patch with angle {angle}\")\n",
    "for roi in rois:\n",
    "    print_attr = True if roi == rois[len(rois) - 1] else False\n",
    "    voxeldict[roi] = VoxelSieve(\n",
    "        NSP,\n",
    "        prf_dict,\n",
    "        roi_masks,\n",
    "        subject=\"subj01\",\n",
    "        roi=roi,\n",
    "        patchloc=\"peripheral\",\n",
    "        max_size=max_size,\n",
    "        min_size=min_size,\n",
    "        patchbound=patchbound,\n",
    "        min_nsd_R2=min_nsd_R2,\n",
    "        min_prf_R2=min_prf_R2,\n",
    "        print_attributes=False,  # print_attr,\n",
    "        fixed_n_voxels=None,\n",
    "        peripheral_center=None,\n",
    "        peri_angle=angle,\n",
    "        peri_ecc=peri_ecc,\n",
    "        leniency=0,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "mask1 = voxeldict[roi].patchmask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10 images, going from 0 to 10\n",
      "Patch eccentricity: 2.0, patch angle: 90\n"
     ]
    }
   ],
   "source": [
    "n_imgs = endimg - startimg\n",
    "print(f\"Processing {n_imgs} images, going from {startimg} to {endimg}\")\n",
    "print(f\"Patch eccentricity: {peri_ecc}, patch angle: {angle}\")\n",
    "select_ices = list(range(startimg, endimg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS BELOW IS FROM THE GET_PRED.PY SCRIPT\n",
    "def draw_circmask(dims, maskrad, offset=(0,0), invert=True):\n",
    "    import numpy as np\n",
    "    y, x = np.ogrid[:dims[0], :dims[1]]\n",
    "    center_x, center_y = dims[1] // 2 + offset[0], dims[0] // 2 + offset[1]\n",
    "    mask = (x - center_x)**2 + (y - center_y)**2 <= maskrad**2\n",
    "    return ~mask if invert else mask\n",
    "\n",
    "def rand_img_list(n_imgs, asPIL:bool = True, add_masks:bool = True, mask_loc: str|np.ndarray = 'center', ecc_max = 1, select_ices = None, in_3d:bool = False):\n",
    "    imgs = []\n",
    "    img_nos = []\n",
    "    for i in range(n_imgs):\n",
    "        img_no = random.randint(0, 27999)\n",
    "        if select_ices is not None:\n",
    "            img_no = select_ices[i]\n",
    "        # img = show_stim(img_no = img_no, hide = 'y')[0]\n",
    "        img = NSP.stimuli.show_stim(img_no = img_no, hide=True, small=False, crop=False)[0]\n",
    "\n",
    "        if i == 0:\n",
    "            dim = img.shape[0]\n",
    "            radius = ecc_max * (dim / 8.4)\n",
    "\n",
    "            if type(mask_loc) == str:\n",
    "                if mask_loc == 'center':\n",
    "                    x = y = (dim + 1)/2\n",
    "                elif mask_loc == 'irrelevant_patch':\n",
    "                    x = y = radius + 10\n",
    "            elif type(mask_loc) == np.ndarray:\n",
    "                bounds = NSP.utils.get_bounding_box(mask_loc)\n",
    "                patch_rad = bounds[1] - bounds[0]\n",
    "                print(patch_rad)\n",
    "                x = bounds[0] + patch_rad/2\n",
    "                y = bounds[2] + patch_rad/2\n",
    "                \n",
    "        if asPIL:\n",
    "            img = Image.fromarray(img)\n",
    "\n",
    "        imgs.append(img)\n",
    "        # img_nos.append(Image.fromarray(img_no))\n",
    "        img_nos.append(img_no)\n",
    "    mask = (make_circle_mask(dim, x, y, radius, fill = 'y', margin_width = 0) == 0)\n",
    "    \n",
    "    if in_3d:\n",
    "        mask = _make_img_3d(mask)\n",
    "    if asPIL:\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "\n",
    "    masks = [mask] * n_imgs\n",
    "    \n",
    "    if add_masks:\n",
    "        return imgs, masks, img_nos\n",
    "    else:\n",
    "        return imgs, img_nos\n",
    "\n",
    "def slice_array_with_mask(arr_in, mask_in):\n",
    "    \"\"\"\n",
    "    Slices a 2D array using a 2D boolean mask with a contiguous square of True values.\n",
    "\n",
    "    :param arr_in: 2D numpy array.\n",
    "    :param mask_in: 2D boolean numpy array of the same shape as arr_in.\n",
    "    :return: Sliced section of arr_in corresponding to the True values in mask_in.\n",
    "    \"\"\"\n",
    "    # Find the indices of the mask where the value is True\n",
    "    rows, cols = np.where(mask_in)\n",
    "    top_left = (min(rows), min(cols))\n",
    "    bottom_right = (max(rows), max(cols))\n",
    "\n",
    "    # Slice the array\n",
    "    return arr_in[top_left[0]:bottom_right[0]+1, top_left[1]:bottom_right[1]+1]\n",
    "\n",
    "def scale_square_mask(mask_in:np.ndarray, scale_fact=np.sqrt(1.5), mask_val=1, min_size=50):\n",
    "    \"\"\"given a square mask, scale width and height with a given factor\n",
    "\n",
    "    in:\n",
    "    - mask_in: ndarray, (2d or 3d)\n",
    "        boolean-type mask image\n",
    "    - mask_val: float/int/bool (default:1)\n",
    "        the value to look for as the definition of in the circle of the mask.\n",
    "    - min_size: int\n",
    "        minimum size of the square mask.\n",
    "\n",
    "    out:\n",
    "    -scaled_mask: ndarray\n",
    "        like the square input mask, but now with a square outline around the mask\n",
    "    \"\"\"\n",
    "    def _do_scaling(_mask_in:np.ndarray, scale_fact=np.sqrt(2), mask_val=1, min_size=50):\n",
    "        \"\"\"inner function doing the actual scaling\"\"\"\n",
    "        mask_out=copy.deepcopy(_mask_in)\n",
    "        nz_rows,nz_cols=np.nonzero(_mask_in==mask_val)\n",
    "        nz_r,nz_c=np.unique(nz_rows),np.unique(nz_cols)\n",
    "        # determine square masks that spans the circle\n",
    "        width, height = nz_r[-1]-nz_r[0], nz_c[-1]-nz_c[0]\n",
    "\n",
    "        # make actual spanning mask a bit larger (delta determined by scale_fact or min_size)\n",
    "        ideal_delta_w = max(np.round(((width*scale_fact) - width)*.5), (min_size - width) // 2)\n",
    "        ideal_delta_h = max(np.round(((height*scale_fact) - height)*.5), (min_size - height) // 2)\n",
    "\n",
    "        # Adjust deltas based on mask's proximity to image borders\n",
    "        delta_w_left = min(ideal_delta_w, nz_c[0])\n",
    "        delta_w_right = min(ideal_delta_w, mask_out.shape[1] - nz_c[-1] - 1)\n",
    "        delta_h_top = min(ideal_delta_h, nz_r[0])\n",
    "        delta_h_bottom = min(ideal_delta_h, mask_out.shape[0] - nz_r[-1] - 1)\n",
    "\n",
    "        # If mask is near the border, expand on the other side\n",
    "        if delta_w_left < ideal_delta_w:\n",
    "            delta_w_right = max(ideal_delta_w * 2 - delta_w_left, delta_w_right)\n",
    "        if delta_w_right < ideal_delta_w:\n",
    "            delta_w_left = max(ideal_delta_w * 2 - delta_w_right, delta_w_left)\n",
    "        if delta_h_top < ideal_delta_h:\n",
    "            delta_h_bottom = max(ideal_delta_h * 2 - delta_h_top, delta_h_bottom)\n",
    "        if delta_h_bottom < ideal_delta_h:\n",
    "            delta_h_top = max(ideal_delta_h * 2 - delta_h_bottom, delta_h_top)\n",
    "\n",
    "        mask_out[int(nz_r[0]-delta_h_top):int(nz_r[-1]+delta_h_bottom),\n",
    "                 int(nz_c[0]-delta_w_left):int(nz_c[-1]+delta_w_right)] = mask_val\n",
    "        # set values to 1, square mask\n",
    "        return(mask_out)\n",
    "\n",
    "    # switch dealing with RGB [colmns,rows,colours] vs grayscale images [columns,rows]\n",
    "    if mask_in.ndim==3:\n",
    "        mask_scaled=_do_scaling(mask_in[:,:,0],scale_fact=scale_fact, mask_val=mask_val, min_size=min_size)\n",
    "        return(_make_img_3d(mask_scaled))\n",
    "    elif mask_in.ndim==2:\n",
    "        return(_do_scaling(mask_in, scale_fact=scale_fact, mask_val=mask_val, min_size=min_size))\n",
    "    else:\n",
    "        raise ValueError('can only understand 3d (RGB) or 2d array images!')\n",
    "\n",
    "def _make_img_3d(mask_in,):\n",
    "    \"\"\"for 2d array, copy to make 3-dimensional\"\"\"\n",
    "    return(np.repeat(mask_in[:,:,np.newaxis],3,axis=2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_radius=100\n",
    "rf_mask=draw_circmask((425,425),mask_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the Model...\n",
      "Running the inpainting file from /rfpred/src/inpainting.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rfpred/envs/rfenv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/rfpred/envs/rfenv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# unet=UNet(checkpoint_name='pconv_circ-places20k.pth',feature_model='alex')\n",
    "# unet=UNet(checkpoint_name='pconv_circ-places20k.pth',feature_model='vgg-conv')\n",
    "unet=UNet(checkpoint_name='pconv_circ-places20k.pth',feature_model='vgg-conv-dense')\n",
    "\n",
    "imgs, masks, img_nos = rand_img_list(n_imgs, asPIL = True, add_masks = True, mask_loc = mask1, ecc_max = 1, select_ices = select_ices, in_3d = False)\n",
    "\n",
    "# from scipy.ndimage import zoom\n",
    "\n",
    "# # Define the new size\n",
    "# new_size = (224, 224)\n",
    "\n",
    "# # Calculate the scaling factors\n",
    "# y_scale = new_size[0] / mask1.shape[0]\n",
    "# x_scale = new_size[1] / mask1.shape[1]\n",
    "\n",
    "# # Resize the array\n",
    "# rf_mask_in = zoom(mask1, (y_scale, x_scale))\n",
    "\n",
    "\n",
    "rf_mask_in = mask1\n",
    "rf_mask_nsd = rf_mask_in == 0\n",
    "xmin,xmax,ymin,ymax = list(get_bounding_box(rf_mask_in))\n",
    "crop_mask = rf_mask_in[ymin:ymax, xmin:xmax] == 1\n",
    "\n",
    "# THIS IS THE ORIGINAL ONE, THE CORRECT CROP\n",
    "# eval_fact=np.sqrt(1.2) # This needs to be in correspondence with the min_size (original eval_fact = 1.5, min_size = 100)\n",
    "eval_fact=np.sqrt(1) # This needs to be in correspondence with the min_size (original eval_fact = 1.5, min_size = 100)\n",
    "\n",
    "# THIS IS THE FULL IMG FEATUREMAP EVALMASK\n",
    "# eval_fact=np.sqrt(18)\n",
    "eval_mask=scale_square_mask(~np.array(masks[0]), min_size=80, scale_fact= eval_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "\n",
    "# # Define the new size\n",
    "# new_size = (224, 224)\n",
    "\n",
    "# # Resize the images\n",
    "# imgs = [img.resize(new_size) for img in imgs]\n",
    "\n",
    "# # Resize the masks\n",
    "# masks = [mask.resize(new_size) for mask in masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 512, 60, 60])\n",
      "torch.Size([10, 512, 7, 7])\n",
      "torch.Size([10, 25088])\n",
      "torch.Size([10, 512, 60, 60])\n",
      "torch.Size([10, 512, 7, 7])\n",
      "torch.Size([10, 25088])\n",
      "torch.Size([10, 512, 60, 60])\n",
      "torch.Size([10, 512, 7, 7])\n",
      "torch.Size([10, 25088])\n",
      "torch.Size([10, 512, 60, 60])\n",
      "torch.Size([10, 512, 7, 7])\n",
      "torch.Size([10, 25088])\n",
      "\n",
      "This took 6.801031589508057 seconds, or 0.11335052649180094 minutes, or 0.0018891754415300158 hours\n",
      "Average time per image: 0.6801031589508056 seconds\n",
      "\n",
      "succeeded\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    " \n",
    "# Run them through the U-Net\n",
    "# payload_nsd = unet.analyse_images(imgs, masks, return_recons=True, eval_mask = None)\n",
    "payload_nsd_crop = unet.analyse_images(imgs, masks, return_recons=True, eval_mask = eval_mask)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "average_time_per_image = (total_time / n_imgs) #/ 2\n",
    "print(f'\\nThis took {total_time} seconds, or {total_time / 60} minutes, or {total_time / 3600} hours')\n",
    "print(f\"Average time per image: {average_time_per_image} seconds\\n\")\n",
    "\n",
    "# Add the specific image indices to the dictionaries. \n",
    "payload_nsd_crop['img_ices'] = img_nos\n",
    "\n",
    "excl = ['recon_dict']\n",
    "payload_light = {k: v for k, v in payload_nsd_crop.items() if k not in excl}\n",
    "\n",
    "print(\"succeeded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.88567e+08, 2.55818e+10, 1.35373e+10, 4.86065e+10, 1.65393e+11,\n",
       "       5.20615e+10, 1.88028e+11, 5.31802e+08, 2.38973e+10, 3.03625e+10],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload_light['content_loss_19_MSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
