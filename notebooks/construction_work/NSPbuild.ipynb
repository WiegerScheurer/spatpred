{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import nibabel as nib\n",
    "import pickle\n",
    "from importlib import reload\n",
    "import h5py\n",
    "from nilearn import plotting\n",
    "import nibabel as nib\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import r2_score\n",
    "from colorama import Fore, Style\n",
    "\n",
    "os.chdir('/home/rfpred')\n",
    "sys.path.append('/home/rfpred')\n",
    "sys.path.append('/home/rfpred/envs/rfenv/lib/python3.11/site-packages/')\n",
    "sys.path.append('/home/rfpred/envs/rfenv/lib/python3.11/site-packages/nsdcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataFetch():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    # Function to get the visual contrast features and predictability estimates\n",
    "    # IMPROVE: make sure that it also works for all subjects later on. Take subject arg, clean up paths.\n",
    "    def features(self):\n",
    "        feature_paths = [\n",
    "            './data/custom_files/all_visfeats_rms.pkl',\n",
    "            './data/custom_files/all_visfeats_rms_crop_prior.pkl',\n",
    "            '/home/rfpred/data/custom_files/all_visfeats_scce.pkl',\n",
    "            '/home/rfpred/data/custom_files/all_visfeats_scce_large.pkl',\n",
    "            '/home/rfpred/data/custom_files/subj01/pred/all_predestims.h5'\n",
    "        ]\n",
    "        return {os.path.basename(file): self._fetch_file(file) for file in feature_paths}\n",
    "    # Function to get the pRF-based voxel selections\n",
    "    # IMPROVE: make sure that it also works for all subjects later on. Take subject arg, clean up paths.\n",
    "    def prf_selections(self):\n",
    "        prf_selection_paths = [\n",
    "            './data/custom_files/subj01/prf_mask_center_strict.pkl',\n",
    "            './data/custom_files/subj01/prf_mask_central_strict_l.pkl',\n",
    "            './data/custom_files/subj01/prf_mask_central_halfloose.pkl',\n",
    "            './data/custom_files/subj01/prf_mask_central_loose.pkl',\n",
    "            './data/custom_files/subj01/prf_mask_periphery_strict.pkl'\n",
    "        ]\n",
    "        return {os.path.basename(file): self._fetch_file(file) for file in prf_selection_paths}\n",
    "    \n",
    "    def _fetch_file(self, file_path:str):\n",
    "        \"\"\"\n",
    "        General function to acquire saved data from various file types\n",
    "        file_type: str, the types of files to be fetched, either features or prf_selections\n",
    "        \"\"\"\n",
    "        _, ext = os.path.splitext(file_path)\n",
    "        \n",
    "        # Check if file is of .h5 type\n",
    "        if ext == '.h5':\n",
    "            with h5py.File(file_path, 'r') as hf:\n",
    "                data = hf.keys()\n",
    "                return {key: np.array(hf[key]).flatten() for key in data}\n",
    "        # Check if file is of .pkl type\n",
    "        elif ext == '.pkl':\n",
    "            with open(file_path, 'rb') as fp:\n",
    "                return pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NatSpatPred():\n",
    "    \n",
    "    def __init__(self, datapath:str='/home/rfpred/data', verbose:bool=False):\n",
    "        self.datafetch = None\n",
    "        self._datapath = datapath\n",
    "        self._verbose = verbose\n",
    "        self.subjects = sorted(os.listdir(f'{datapath}/natural-scenes-dataset/nsddata/ppdata'), key=lambda s: int(s.split('subj')[-1]))\n",
    "        self.rois = None\n",
    "        self.roi_masks = None\n",
    "        self.prf_dict = None\n",
    "        self.anat_temps = None\n",
    "        self.feats = None\n",
    "        self.prfloc_vox_selections = None\n",
    "        self.attributes = None\n",
    "        self.attributes_unfiltered = None\n",
    "\n",
    "\n",
    "    # TODO: Expand this initialise in such way that it creates all the globally relevant attributes by calling on methods from the\n",
    "    # nested classes\n",
    "    def initialise(self):\n",
    "        self.datafetch = DataFetch()\n",
    "        self.rois, self.roi_masks = self._make_visrois_dict()\n",
    "        self.prf_dict = self._write_prf_dict()\n",
    "        self.anat_temps = self._get_anat_templates()\n",
    "        self.feats = self.datafetch.features()\n",
    "        self.prfloc_vox_selections = self.datafetch.prf_selections()\n",
    "        self.attributes = [attr for attr in dir(self) if not attr.startswith('_')] # Filter out both the 'dunder' and hidden methods\n",
    "        self.attributes_unfiltered = [attr for attr in dir(self) if not attr.startswith('__')] # Filter out only the 'dunder' methods\n",
    "        print(f'Naturalistic Spatial Prediction class: {Fore.LIGHTGREEN_EX}Initialised{Style.RESET_ALL}')\n",
    "        print('\\nClass contains the following attributes:')\n",
    "        for attr in self.attributes:\n",
    "            print(f\"{Fore.LIGHTWHITE_EX}\\t.{attr}{Style.RESET_ALL}\")\n",
    "\n",
    "\n",
    "    def _make_visrois_dict(self):\n",
    "        rois = []\n",
    "        binary_masks = {}\n",
    "\n",
    "        for subj_no in range(1, len(self.subjects) + 1):\n",
    "            if self._verbose:\n",
    "                print(f'Fetching roi masks for subject {Fore.LIGHTBLUE_EX}{subj_no}{Style.RESET_ALL}')\n",
    "            mask_dir = f'{self._datapath}/natural-scenes-dataset/nsddata/ppdata/subj0{subj_no}/func1mm/roi'\n",
    "\n",
    "            # read in and sort all the filenames in the mapped masks folder for each subject\n",
    "            non_binary_masks = sorted([file for file in os.listdir(mask_dir) if '_mask.nii' in file])\n",
    "            subj_binary_masks = {}\n",
    "\n",
    "            for idx, mask_file in enumerate(non_binary_masks):\n",
    "                # Load the mask file\n",
    "                subj_binary_masks[non_binary_masks[idx][:-7]] = (nib.load(os.path.join(mask_dir, mask_file)).get_fdata()).astype(int)\n",
    "            if self._verbose:\n",
    "                # Print the amount of non-zero voxels in the roi\n",
    "                for key, subj_binary_mask in subj_binary_masks.items():\n",
    "                    print(f\" - Voxels in {Fore.BLUE}{key[:2]}{Style.RESET_ALL}: {np.sum(subj_binary_mask)}\")\n",
    "                    \n",
    "            binary_masks[f'subj0{subj_no}'] = subj_binary_masks\n",
    "            rois = [roi[:2] for roi in binary_masks['subj01'].keys()]\n",
    "        return rois, binary_masks\n",
    "    \n",
    "    # Function to create a list solely containing roi-based voxels\n",
    "    def _roi_filter(self, roi_mask, input_array, nan2null:bool=False):\n",
    "        roi_ices = np.argwhere(roi_mask != 0)\n",
    "\n",
    "        # Create list that only contains the voxels of the specific roi\n",
    "        roi_ar = np.column_stack((roi_ices, input_array[roi_ices[:, 0], roi_ices[:, 1], roi_ices[:, 2]]))\n",
    "\n",
    "        # Turn the nan values into zeros for the angle parameter\n",
    "        if nan2null:\n",
    "            output_roi = np.nan_to_num(roi_ar, nan=0)\n",
    "            \n",
    "        # Filter away the nan values\n",
    "        output_roi = roi_ar[~np.isnan(roi_ar).any(axis=1)]\n",
    "        rounded_output_roi = np.round(roi_ar, 5)\n",
    "        \n",
    "        # Set print options to control precision and suppress scientific notation\n",
    "        np.set_printoptions(precision=5, suppress=True)\n",
    "        \n",
    "        return rounded_output_roi\n",
    "        \n",
    "    # Function to load in nifti (.nii.gz) data and create some useful variables \n",
    "    def _get_dat(self, path:str):\n",
    "        full_dat = nib.load(path)\n",
    "        dat_array = full_dat.get_fdata()\n",
    "        \n",
    "        # Calculate the range of values\n",
    "        flat_arr = dat_array[~np.isnan(dat_array)]\n",
    "        dat_dim = dat_array.shape\n",
    "\n",
    "        return full_dat, dat_array, dat_dim, {'min': round(np.nanmin(flat_arr),7), 'max': np.nanmax(flat_arr), 'mean': round(np.nanmean(flat_arr),5)}\n",
    "    \n",
    "    # This function provides a dictionary with all the pRF data for all subjects and rois\n",
    "    def _write_prf_dict(self):\n",
    "        prf_dict = {}\n",
    "\n",
    "        # Make a loop to go over all the subjects\n",
    "        for subject in self.subjects:\n",
    "            prf_dict[subject] = {}\n",
    "            prf_dict[subject]['nsd_dat'] = {}\n",
    "            \n",
    "            # Initialize dictionaries if they don't exist\n",
    "            prf_dict[subject]['proc'] = {}\n",
    "\n",
    "            # Get the overall prf results, save them in a dict\n",
    "            prf_types = ['angle', 'eccentricity', 'exponent', 'gain', 'meanvol', 'R2', 'size']\n",
    "\n",
    "            for prf_type in prf_types:\n",
    "                prf_path = f'{self._datapath}/natural-scenes-dataset/nsddata/ppdata/{subject}/func1mm/prf_{prf_type}.nii.gz'\n",
    "                prf_dat, prf_ar, prf_dim, prf_range = self._get_dat(prf_path)\n",
    "                prf_dict[subject]['nsd_dat'][prf_type] = {\n",
    "                    'prf_dat': prf_dat,\n",
    "                    'prf_ar': prf_ar,\n",
    "                    'prf_dim': prf_dim,\n",
    "                    'prf_range': prf_range\n",
    "                }\n",
    "            roi_list =  [f'{roistr}_mask' for roistr in self.rois]\n",
    "            for roi in roi_list:\n",
    "                prf_dict[subject]['proc'][roi] = {\n",
    "                    prf_type : None for prf_type in prf_types\n",
    "                } \n",
    "                for prf_type in prf_types:\n",
    "                    prf_dict[subject]['proc'][roi][prf_type] = self._roi_filter(self.roi_masks[subject][roi], prf_dict[subject]['nsd_dat'][prf_type]['prf_ar'])\n",
    "\n",
    "            # Calculate the linear pRF sigma values, these tend to be smaller and don't take\n",
    "            # into account the nonlinear relationship between input and neural respons\n",
    "                lin_sigmas = prf_dict[subject]['proc'][roi]['size'][:,3] * np.sqrt(prf_dict[subject]['proc'][roi]['exponent'][:,3])\n",
    "                prf_dict[subject]['proc'][roi]['lin_sigma'] = np.column_stack([prf_dict[subject]['proc'][roi]['size'][:,0:3], lin_sigmas])\n",
    "\n",
    "        return prf_dict\n",
    "    \n",
    "    def _get_anat_templates(self):\n",
    "        # Get subject-specific T1 anatomical maps to use as base for later overlays\n",
    "        anat_temps = {}\n",
    "        for subject in self.prf_dict.keys():\n",
    "            anat_temps[subject] = nib.load(f'{self._datapath}/natural-scenes-dataset/nsddata/ppdata/{subject}/func1mm/T1_to_func1mm.nii.gz')\n",
    "        return anat_temps\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naturalistic Spatial Prediction class: \u001b[92mInitialised\u001b[0m\n",
      "\n",
      "Class contains the following attributes:\n",
      "\u001b[97m\t.anat_temps\u001b[0m\n",
      "\u001b[97m\t.attributes\u001b[0m\n",
      "\u001b[97m\t.attributes_unfiltered\u001b[0m\n",
      "\u001b[97m\t.datafetch\u001b[0m\n",
      "\u001b[97m\t.feats\u001b[0m\n",
      "\u001b[97m\t.initialise\u001b[0m\n",
      "\u001b[97m\t.prf_dict\u001b[0m\n",
      "\u001b[97m\t.prfloc_vox_selections\u001b[0m\n",
      "\u001b[97m\t.roi_masks\u001b[0m\n",
      "\u001b[97m\t.rois\u001b[0m\n",
      "\u001b[97m\t.subjects\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "NSP = NatSpatPred()\n",
    "NSP.initialise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 186, 148)\n",
      "(145, 186, 148)\n"
     ]
    }
   ],
   "source": [
    "print(NSP.prfloc_vox_selections['prf_mask_center_strict.pkl']['subj01']['V1_mask'].shape)\n",
    "\n",
    "print(NSP.roi_masks['subj01']['V1_mask'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 10375.7265625 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import os\n",
    "\n",
    "def print_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"Memory usage: {process.memory_info().rss / 1024 ** 2} MB\")\n",
    "\n",
    "print_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_user_variables():\n",
    "    print(\"\\n\".join(\"%s: %s\" % item for item in globals().items() if not item[0].startswith(\"__\")))\n",
    "\n",
    "# print_user_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU usage: 0.0%\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import os\n",
    "\n",
    "def print_cpu_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"CPU usage: {process.cpu_percent()}%\")\n",
    "\n",
    "print_cpu_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of x: 272 bytes\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "x = \"Hello, world!\"\n",
    "print(f\"Memory usage of x: {sys.getsizeof(NSP.roi_masks)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet(\n",
    "#   (features): Sequential(\n",
    "#     (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "#     (1): ReLU(inplace=True)\n",
    "#     (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "#     (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "#     (4): ReLU(inplace=True)\n",
    "#     (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "#     (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (7): ReLU(inplace=True)\n",
    "#     (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (9): ReLU(inplace=True)\n",
    "#     (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (11): ReLU(inplace=True)\n",
    "#     (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "#   )\n",
    "#   (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
    "#   (classifier): Sequential(\n",
    "#     (0): Dropout(p=0.5, inplace=False)\n",
    "#     (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
    "#     (2): ReLU(inplace=True)\n",
    "#     (3): Dropout(p=0.5, inplace=False)\n",
    "#     (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "#     (5): ReLU(inplace=True)\n",
    "#     (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "#   )\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
